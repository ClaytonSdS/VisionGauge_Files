{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":680726,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":514490,"modelId":529138}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==============================\n# Básicos\n# ==============================\nimport os\nimport time\nfrom datetime import datetime\nimport copy\nfrom collections import OrderedDict\nimport random\nfrom torch.optim.lr_scheduler import LinearLR, SequentialLR, CosineAnnealingLR\nfrom tqdm.notebook import tqdm\nfrom albumentations.pytorch import ToTensorV2\nfrom PIL import Image\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom torch.utils.data import DataLoader, TensorDataset\nimport hashlib\n\n# ==============================\n# NumPy e Pandas\n# ==============================\nimport numpy as np\nimport pandas as pd\nfrom dataclasses import dataclass\nimport matplotlib.pyplot as plt \n\n# ==============================\n# Scikit-learn\n# ==============================\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\n\n# ==============================\n# PyTorch\n# ==============================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW as AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.optim import Adam\nfrom torch import amp\nfrom torchvision import models\nfrom torch.utils.data import Subset\n\n# ==============================\n# TensorFlow\n# ==============================\nimport tensorflow as tf\n\n# ==============================\n# Utilitários\n# ==============================\nfrom tqdm.notebook import tqdm\nimport albumentations as A\n\n\nimport pandas as pd\n\n# mostra o texto completo em cada coluna, sem cortar\npd.set_option('display.max_colwidth', None)\n\n# aumenta o número de colunas visíveis\npd.set_option('display.max_columns', None)\n\n# aumenta a largura total do display\npd.set_option('display.width', 2000)\n\n\nimport os\nimport pandas as pd\n\nimport os\nimport pandas as pd\n\ndef Folder2DataFrame(path):\n\n    # pega só as pastas do primeiro nível (ex: ['train', 'valid'])\n    folders = [\n        item for item in os.listdir(path)\n        if os.path.isdir(os.path.join(path, item))\n    ]\n\n    if len(folders) < 5:\n        print(f\"Pastas encontradas: {folders}\")\n\n    df = pd.DataFrame(columns=['file', 'deltaH_cm'])\n\n    # percorre cada pasta de primeiro nível\n    for fold in folders:\n        fold_path = os.path.join(path, fold)\n\n        # agora desce dentro dessa pasta e pega os arquivos\n        for raiz, pastas, arquivos in os.walk(fold_path):\n\n            # se tiver arquivos, eles são as imagens\n            for arquivo in arquivos:\n                caminho_imagem = os.path.join(raiz, arquivo)\n\n                # pega o rótulo a partir do nome da pasta\n                label = os.path.basename(raiz)\n\n                df.loc[len(df)] = [caminho_imagem, float(label)]\n\n    return df\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:31:08.238991Z","iopub.execute_input":"2025-12-12T23:31:08.239683Z","iopub.status.idle":"2025-12-12T23:31:32.460815Z","shell.execute_reply.started":"2025-12-12T23:31:08.239659Z","shell.execute_reply":"2025-12-12T23:31:32.460179Z"}},"outputs":[{"name":"stderr","text":"2025-12-12 23:31:18.628066: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765582278.817688      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765582278.869151      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"!pip install roboflow --quiet\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"WrSsYZ8GgJHC2S5jFe0x\")\nproject = rf.workspace(\"visiongauge\").project(\"utm_dataset-ooorv\")\nversion = project.version(16)\ndataset = version.download(\"folder\")\n                \n\n                ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:31:32.462260Z","iopub.execute_input":"2025-12-12T23:31:32.462862Z","iopub.status.idle":"2025-12-12T23:31:42.409165Z","shell.execute_reply.started":"2025-12-12T23:31:32.462841Z","shell.execute_reply":"2025-12-12T23:31:42.408469Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ns3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2025.10.0 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\nloading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Aplicar Crop/Translation Aug","metadata":{}},{"cell_type":"code","source":"DO_IT = False\ndataset_name = \"UTM_Dataset-16\"\n\nif DO_IT:\n    my_current_dir = os.getcwd()\n    \n    \n    # Função para aplicar zoom:\n    def apply_zoom(img, zoom_factor):\n        h, w, _ = img.shape\n        new_h = int(h * zoom_factor)\n        new_w = int(w * zoom_factor)\n    \n        img_resized = cv2.resize(img, (new_w, new_h))\n    \n        # Crop ou pad para voltar ao tamanho original\n        if zoom_factor < 1.0:\n            # Pad\n            pad_h = (h - new_h) // 2\n            pad_w = (w - new_w) // 2\n            padded = np.zeros((h, w, 3), dtype=img.dtype)\n            padded[pad_h:pad_h + new_h, pad_w:pad_w + new_w] = img_resized\n            return padded\n        \n        else:\n            # Crop\n            start_row = (new_h - h) // 2\n            start_col = (new_w - w) // 2\n            return img_resized[start_row:start_row + h, start_col:start_col + w]\n    \n    # Função para cortar a image  e pular linhas\n    def crop_skip_lines(img, skip=100, image_size=400):\n        h, w, _ = img.shape\n        cropped = img[skip:skip + image_size, :image_size, :]\n        return cropped\n\n    def crop_skip_lines(img, skip=100, image_size=400):\n        h, w, _ = img.shape\n\n        # altura disponível depois do skip\n        usable_height = h - skip\n    \n        # tamanho do quadrado é o menor entre largura e altura disponível\n        size = min(w, usable_height)\n    \n        # crop começa após o skip e pela esquerda\n        start_y = skip\n        start_x = 0\n    \n        cropped = img[start_y:start_y + size, start_x:start_x + size, :]\n        return cropped\n    \n    \n    target = 500 - 450 # -- 276\n    skips = [i for i in range(0, target, 5)]\n    print(f\"O número de skips rows é: {len(skips)}\")\n    \n    zooms = [0.9, 1.2, 1.4, 1.6]\n    print(f\"O número de zooms é: {len(zooms)}\")\n    \n    sets = [\"train\", \"valid\", \"test\"]\n    \n    import random\n    import os\n    import cv2\n    import tqdm\n    \n    resizes = [(size, size) for size in range(110, 251, 10)]\n    print(f\"O número de crops é: {len(resizes)}\")\n    \n    #============================================================================================================\n    # APLICAR OS CROPS DIFERENTES\n    for set_name in sets:\n        print(f\"[RESIZE] Processando {set_name}\")\n    \n        base_dir = os.path.join(my_current_dir, dataset_name, set_name)\n    \n        for folder in tqdm.tqdm(os.listdir(base_dir)):\n            current_folder = os.path.join(base_dir, folder)\n    \n            for image in os.listdir(current_folder):\n                if image.startswith(\"image\"):\n                    image_path = os.path.join(current_folder, image)\n                    \n                    img = cv2.imread(image_path)\n                    if img is None:\n                        print(f\"Erro ao ler: {image_path}\")\n                        continue\n                    \n                    # extrair número da imagem\n                    image_number = image.split(\"_\")[2]\n                    resized_img = cv2.resize(img, (95, 95))\n                    resized_img = cv2.resize(img, (120, 120))\n    \n                        # salvar\n                    image_name = f\"resize_{95}to{120}_image_{image_number}\"\n                    save_path = os.path.join(current_folder, f\"{image_name}.jpg\")\n    \n                    cv2.imwrite(save_path, resized_img)\n    \n    \n    \n    #============================================================================================================\n    # Aplicar zooms + SKIP ROWS\n    for set in sets:\n        print(f\"[ZOOM + SKIP] Processando {set}\")\n        \n        for folder in tqdm.tqdm(os.listdir(os.path.join(my_current_dir, dataset_name, set))):\n            current_folder = os.path.join(my_current_dir,dataset_name, set, folder)\n        \n            for image in os.listdir(current_folder):\n                if image.split(\"_\")[0].startswith(\"image\"):\n                    image_path = os.path.join(current_folder, image)\n                    image_reader = cv2.imread(image_path)\n                    image_number = image.split(\"_\")[2]\n        \n                    for zoom in zooms:\n                        img_zoomed = apply_zoom(image_reader, zoom)\n        \n                        # resize\n                        img_zoomed = cv2.resize(img_zoomed, (224, 224))\n        \n                        # salvar a imagem\n                        zoom_str = str(zoom).replace(\".\", \"_\")\n                        image_name = \"zoom_\" + zoom_str + \"image\" + image_number\n                        save_path = os.path.join(my_current_dir, dataset_name, set, folder, f\"{image_name}.jpg\")\n        \n                        # salvar imagem\n                        cv2.imwrite(save_path, img_zoomed)\n    \n        \n        #============================================================================================================\n        # Aplicar Skip Rows \n        for folder in tqdm.tqdm(os.listdir(os.path.join(my_current_dir, dataset_name, set))):\n            current_folder = os.path.join(my_current_dir, dataset_name, set, folder)\n        \n            for image in os.listdir(current_folder):\n                if image.split(\"_\")[0].startswith(\"image\"):\n                    image_path = os.path.join(current_folder, image)\n                    image_reader = cv2.imread(image_path)\n                    image_number = image.split(\"_\")[2]\n        \n                    # Aplicar cortes pulando linhas\n                    for skip in skips:\n                        img_cropped = crop_skip_lines(image_reader, skip=skip)\n        \n                        # resize\n                        img_cropped = cv2.resize(img_cropped, (224, 224))\n        \n                        # salvar a imagem\n                        skip_str = str(skip)\n                        image_name = \"skip_\" + skip_str + \"_image\" + image_number\n                        save_path = os.path.join(my_current_dir, dataset_name, set, folder, f\"{image_name}.jpg\")\n        \n                        # salvar imagem\n                        cv2.imwrite(save_path, img_cropped)\n                    \n    print(\"Finalizado o aumento de dados com zoom.\")    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:31:42.410309Z","iopub.execute_input":"2025-12-12T23:31:42.410522Z","iopub.status.idle":"2025-12-12T23:31:42.426730Z","shell.execute_reply.started":"2025-12-12T23:31:42.410502Z","shell.execute_reply":"2025-12-12T23:31:42.425963Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Settings","metadata":{}},{"cell_type":"code","source":"from dataclasses import dataclass\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\n# ================= CONFIG =================\n\nclass SETTINGS:\n    def __init__(self):\n        self.USE_SCALER = False\n        \n        self.DATASET_NAME = \"7.5k\" # [3k, 6k, 7.5k]\n\n        self.TRAIN_DATASET_DIR = f\"/kaggle/working/{dataset_name}//train\"\n        self.VALID_DATASET_DIR = f\"/kaggle/working/{dataset_name}//valid\"\n        self.TEST_DATASET_DIR = f\"/kaggle/working/{dataset_name}//test\"\n        \n        self.TRAIN_DATASET = Folder2DataFrame(self.TRAIN_DATASET_DIR)\n        self.VALID_DATASET = Folder2DataFrame(self.VALID_DATASET_DIR)\n        self.TEST_DATASET = Folder2DataFrame(self.TEST_DATASET_DIR)\n\n        # Dataset para splitar para caso for utilizar sklearn split\n        self.DATASET = pd.concat([self.TRAIN_DATASET, self.VALID_DATASET], ignore_index=True)\n        print(self.DATASET.index.min(), self.DATASET.index.max()) \n        \n        # SCALER CONFIG\n        self.SCALER = StandardScaler()\n        self.SCALER.fit(self.TRAIN_DATASET[\"deltaH_cm\"].values.reshape(-1, 1))\n        \n        if self.USE_SCALER:\n            self.TRAIN_DATASET[\"DELTA_SCALED\"] = self.SCALER.transform(self.TRAIN_DATASET[\"deltaH_cm\"].values.reshape(-1, 1))\n            self.VALID_DATASET[\"DELTA_SCALED\"] = self.SCALER.transform(self.VALID_DATASET[\"deltaH_cm\"].values.reshape(-1, 1))\n\n        VERBOSE = False\n        \n        # TRAINING\n        self.TRAINING = True\n        self.BATCH_SIZE = 64\n        self.K_FOLD = 1\n        self.NUM_EPOCHS = 30\n        self.LR = 1e-5\n        self.MAX_CACHE = 100\n        self.PATIENCE = 10\n\n    \nSETTINGS = SETTINGS()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:31:42.428389Z","iopub.execute_input":"2025-12-12T23:31:42.428806Z","iopub.status.idle":"2025-12-12T23:36:37.804210Z","shell.execute_reply.started":"2025-12-12T23:31:42.428781Z","shell.execute_reply":"2025-12-12T23:36:37.803361Z"}},"outputs":[{"name":"stdout","text":"0 155007\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(SETTINGS.TRAIN_DATASET.shape)\nprint(SETTINGS.VALID_DATASET.shape)\nprint(SETTINGS.TEST_DATASET.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:36:37.805108Z","iopub.execute_input":"2025-12-12T23:36:37.805457Z","iopub.status.idle":"2025-12-12T23:36:37.809867Z","shell.execute_reply.started":"2025-12-12T23:36:37.805430Z","shell.execute_reply":"2025-12-12T23:36:37.809054Z"}},"outputs":[{"name":"stdout","text":"(121664, 2)\n(33344, 2)\n(17248, 2)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Arch","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\nfrom torchvision import models\n\nclass NewDirectModel(nn.Module):\n    def __init__(self, backbone_name: str, image_size:tuple=(120, 120), unfreeze_all:bool=False, use_head:bool = False, debug: bool = False):\n        super().__init__()\n        self.model_name = backbone_name\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.debug = debug\n        self.use_head = use_head\n\n        self.unfreeze_all = unfreeze_all # descongelar tudo e manter o shape da arquitetura\n\n        # placeholder image_size; será definido em load_backbone\n        self.image_size = image_size\n\n        # Carrega o backbone e constrói a head\n        self.load_backbone()\n\n        self.to(self.device)\n\n    def build_head(self, output_features):\n        self.head = nn.Sequential(\n                    nn.Linear(output_features, 256),\n                    nn.ReLU(inplace=True),\n                    nn.Dropout(0.2),\n                    nn.Linear(256, 256 // 2),\n                    nn.ReLU(inplace=True),\n                    nn.Dropout(0.2),\n                    nn.Linear(256 // 2, 1),\n                )\n\n        for p in self.head.parameters():\n                p.requires_grad = True\n\n        print(\"Descongelado os parâmetros de head\")\n\n        parameters = sum(p.numel() for p in self.head.parameters() if p.requires_grad)\n        print(f\"Head MLP Parâmetros Treináveis: {parameters}\")\n    \n\n    def forward(self, x):\n        x = x.to(self.device)\n\n        # Forward: Backbone -> Head -> Output\n        if self.use_head:\n            features = self.backbone(x)\n            return self.head(features)\n\n           \n        # Forward: Backbone -> Output\n        else:\n            return self.backbone(x)\n        \n\n    def load_model(self, path_or_ckpt):\n        # carregar checkpoint\n        if isinstance(path_or_ckpt, str):\n            ckpt = torch.load(path_or_ckpt, map_location=self.device)\n            \n        elif isinstance(path_or_ckpt, dict):\n            ckpt = path_or_ckpt\n            \n        else:\n            raise ValueError(\"path_or_ckpt deve ser str (path) ou dict (checkpoint)\")\n\n        # manter checkpoint completo\n        self.checkpoint = ckpt\n\n        # metadata e flags\n        meta = ckpt.get(\"metadata\", {})\n        self.model_name = meta.get(\"backbone_name\", self.model_name)\n\n        # reconstruir arquitetura igual ao treino\n        self.load_backbone()\n\n        # carregar pesos do model_state (compatibilidade permissiva)\n        model_state = ckpt.get(\"model_state\", None)\n        if model_state is not None:\n            self.load_state_dict(model_state, strict=False)\n\n        self.to(self.device)\n        #self.eval()\n\n        if self.debug:\n            print(f\"Modelo restaurado. Backbone: {self.model_name} - head: {'sim' if hasattr(self,'head') and self.head is not None else 'não'}\")\n        \n        return self\n        \n\n    def load_backbone(self):\n        name = self.model_name.lower()\n\n        def print_trainable_layers(model):\n            print(\"Parâmetros treináveis:\")\n            for n, p in model.named_parameters():\n                if p.requires_grad:\n                    print(f\"{n} -> {p.shape}\")\n            print(\"--------------------------------------------------\")\n\n\n        # self.gradient_set(classifier_layer = m.fc, model=m, out_feats = out_feats)\n\n        # VIT =======================================================================================================================================\n        if name in (\"vit\", \"vit_b16\", \"vit_b_16\"):\n            m = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n\n            # tamanho padrão do ViT\n            self.image_size = (224, 224)\n            \n            # hidden_dim = tamanho do embedding\n            out_feats = m.hidden_dim\n    \n            # se usar head MLP → só extrai features\n            if self.use_head:\n                m.heads = nn.Identity()\n                self.build_head(output_features=out_feats)\n            else:\n                # regressão direta\n                m.heads = nn.Linear(out_feats, 1)\n    \n            # congelar tudo inicialmente\n            for p in m.parameters():\n                p.requires_grad = False\n    \n            # unfreeze total → fine-tuning completo\n            if self.unfreeze_all:\n                for p in m.parameters():\n                    p.requires_grad = True\n                if self.debug:\n                    print(\"[ViT] Descongelado COMPLETO.\")\n    \n            # unfreeze parcial → melhor prática\n            else:\n                 # últimas 2 camadas do encoder\n                for p in m.encoder.layers[-2:].parameters(): \n                    p.requires_grad = True\n    \n                # heads sempre treinável (Linear ou Identity->Head)\n                for p in m.heads.parameters():\n                    p.requires_grad = True\n    \n                if self.debug:\n                    print(\"[ViT] Encoder descongelado. Patch Embedding congelado.\")\n\n            self.backbone = m\n\n\n        # RESNET =======================================================================================================================================\n        elif name in (\"resnet\", \"resnet18\"):\n            self.image_size = (120, 120)\n            m = models.resnet18(pretrained=True)\n        \n            out_feats = m.fc.in_features\n        \n            # Usar head como MLP para regressão\n            if self.use_head:\n                m.fc = nn.Identity() # remover a última FC\n                self.build_head(output_features=out_feats) # criar head mlp\n                \n            # Sem head: usa FC de saída única -> (1280, 1)\n            else:\n                m.fc = nn.Linear(out_feats, 1)\n        \n            # Congelar tudo\n            for p in m.parameters():\n                p.requires_grad = False\n        \n            # Descongelar tudo se  unfreeze_all == True\n            if self.unfreeze_all:\n                for p in m.parameters():\n                    p.requires_grad = True\n        \n            # Descongelar apenas o classificador (FC)\n            else:\n                for param in m.layer3.parameters():\n                  param.requires_grad = True\n\n                print(\"Resnet Features [3] Descongelado\")\n\n                for param in m.layer4.parameters():\n                  param.requires_grad = True\n                    \n                print(\"Resnet Features [4] Descongelado\")\n\n                for p in m.fc.parameters():\n                    p.requires_grad = True\n\n            self.backbone = m\n    \n\n        # EfficientNet =======================================================================================================================================\n        elif name in (\"efficientnet_lite\", \"efficientnet_b0\"):\n            self.image_size = (120, 120)\n            m = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n        \n            # nº de features que saem antes da FC final (classificador)\n            out_feats = m.classifier[1].in_features\n        \n            # Usar head como MLP para regressão\n            if self.use_head:\n                # Queremos usar a head MLP: remover a FC final e ficar só com features\n                m.classifier[1] = nn.Identity() \n                \n                # Cria a MLP de regressão\n                self.build_head(output_features=out_feats)\n        \n            else:\n                # Não vamos usar head: ajusta a FC para saída de 1\n                m.classifier[1] = nn.Linear(out_feats, 1)\n        \n            # Congelar todos os parâmetros\n            for p in m.parameters():\n                p.requires_grad = False\n\n            # Descongelar toda a arquitetura se unfreeze_all == True\n            if self.unfreeze_all:\n                print(\"[EfficientNet] backbone descongelado (todos os params treináveis)\")\n                for p in m.parameters():\n                    p.requires_grad = True\n                    \n            # Descongelar apenas o classificador (FC)\n            else:\n                # descongelar camada 6, 7 e 8\n                for idx in [6, 7, 8]:\n                    for param in m.features[idx].parameters():\n                        param.requires_grad = True\n                    print(f\"[EfficientNet] Features [{idx}] Descongelado\")\n\n\n                # descongelar o classificador\n                for p in m.classifier[1].parameters():\n                    p.requires_grad = True           # deixa a FC treinável\n                print(\"[EfficientNet] classificador (fc) descongelado\")\n\n            self.backbone = m\n\n        else:\n            raise ValueError(f\"Backbone '{self.model_name}' inválido.\")\n\n    def parameter_groups(self, lr_backbone: float = 1e-5, lr_head: float = 1e-3):\n        backbone_params = []\n        head_params = []\n    \n        # --- Caso 1: use_head = True ---\n        if self.use_head:\n            # Tudo que é treinável do backbone -> lr_backbone\n            for p in self.backbone.parameters():\n                if p.requires_grad:\n                    backbone_params.append(p)\n    \n            # Head MLP -> lr_head\n            if hasattr(self, \"head\"):\n                for p in self.head.parameters():\n                    if p.requires_grad:\n                        head_params.append(p)\n    \n        # --- Caso 2: use_head = False ---\n        else:\n            for name, p in self.backbone.named_parameters():\n                if not p.requires_grad:\n                    continue\n    \n                # última camada do backbone vai pro head\n                if (\n                    name.startswith(\"fc.\") or\n                    name.startswith(\"classifier.1.\") or\n                    name.startswith(\"heads.\")\n                ):\n                    head_params.append(p)\n                else:\n                    backbone_params.append(p)\n    \n        groups = []\n        if backbone_params:\n            groups.append({\"params\": backbone_params, \"lr\": lr_backbone})\n        if head_params:\n            groups.append({\"params\": head_params, \"lr\": lr_head})\n    \n        print(\"Backbone params:\", len(backbone_params))\n        print(\"Head params:\", len(head_params))\n    \n        return groups\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:36:37.811479Z","iopub.execute_input":"2025-12-12T23:36:37.811815Z","iopub.status.idle":"2025-12-12T23:36:37.836937Z","shell.execute_reply.started":"2025-12-12T23:36:37.811790Z","shell.execute_reply":"2025-12-12T23:36:37.836073Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(\"================\")\nm = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\nprint(m.classifier)\nprint(f\" o número de features é: {m.classifier[1].in_features}\")\n\nprint(\"================\")\nm = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\nm.classifier[1] = nn.Identity()\nprint(m.classifier[1])\n\nprint()\nprint(m.classifier)\n\nprint(\"================\")\nm = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\nm.classifier[1] = nn.Linear(1200, 1)\nprint(m.classifier)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:36:37.837881Z","iopub.execute_input":"2025-12-12T23:36:37.838175Z","iopub.status.idle":"2025-12-12T23:36:38.434202Z","shell.execute_reply.started":"2025-12-12T23:36:37.838153Z","shell.execute_reply":"2025-12-12T23:36:38.433542Z"}},"outputs":[{"name":"stdout","text":"================\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 183MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Sequential(\n  (0): Dropout(p=0.2, inplace=True)\n  (1): Linear(in_features=1280, out_features=1000, bias=True)\n)\n o número de features é: 1280\n================\nIdentity()\n\nSequential(\n  (0): Dropout(p=0.2, inplace=True)\n  (1): Identity()\n)\n================\nSequential(\n  (0): Dropout(p=0.2, inplace=True)\n  (1): Linear(in_features=1200, out_features=1, bias=True)\n)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"def hash_to_percent(x):\n    h = hashlib.md5(str(x).encode()).hexdigest()\n    return int(h, 16) % 100\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, data, image_size:tuple=(120,120), DATASET_PATH=SETTINGS.TRAIN_DATASET_DIR,\n                 cache_size=50, use_transform=True, use_scaler=True, SPLIT_OPTION:str='SKLEARN', is_valid:bool=True):\n\n        self.data = data.reset_index(drop=True)\n        self.image_size = image_size \n        \n        self.DATASET_PATH = DATASET_PATH\n        self.cache_size = cache_size\n        self._cache = OrderedDict()\n\n        self.USE_TRANSFORM = use_transform\n        self.USE_SCALER = use_scaler\n\n        self.SPLIT_OPTION = SPLIT_OPTION\n\n\n        height, width = image_size if isinstance(image_size, tuple) else (image_size, image_size)\n\n\n        if isinstance(image_size, (tuple, list)):\n            self.height, self.width = image_size\n            \n        else:\n            self.height = self.width = image_size\n\n\n        # usar hash\n        if self.SPLIT_OPTION.upper() == 'HASHSPLIT':\n            self.__hashSplit__()\n\n        # usar sklearn split\n        elif self.SPLIT_OPTION.upper() == 'SKLEARNSPLIT':\n            self.__kFoldSplit__()\n    \n\n        # Albumentations COMPOSE (criado uma vez)\n        if is_valid:\n            # TRANSFORMAÇÕES DE VALIDAÇÃO (SEM AUGMENTAÇÃO)\n            self.transform = A.Compose([\n                A.Resize(self.height, self.width),\n                A.Normalize(mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225]),\n                ToTensorV2(),\n            ])\n        else:\n            # TRANSFORMAÇÕES DE TREINO (COM AUGMENTAÇÃO)\n            self.transform = A.Compose([\n                A.RandomBrightnessContrast(0.1,0.2,p=0.5),\n                A.RGBShift(5,5,5,p=0.3),\n                \n                A.ISONoise(color_shift=(0.005, 0.01), intensity=(0.05, 0.1), p=0.7),\n\n                #A.OneOf([A.ShiftScaleRotate(rotate_limit=15, shift_limit=0.03, scale_limit=0.05, p=1),\n                         #A.Perspective(scale=(0.01, 0.03), p=1)], p=0.4),\n                \n\n                A.Defocus(radius=(1, 2), alias_blur=(0.05, 0.2), p=0.1),\n                A.PlanckianJitter(mode=\"blackbody\",temperature_limit=(4500, 7500),sampling_method=\"uniform\"),\n\n                # Aplicar Resize e Normalize Padrão\n                A.Resize(self.height, self.width),\n                A.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n                ToTensorV2(),\n            ])\n            \n\n    def __hashSplit__(self, val_percent=30):\n        train_idx = []\n        val_idx = []\n    \n        for i, row in self.data.iterrows():\n            file_id = row[\"file\"]\n            p = hash_to_percent(file_id)\n    \n            if p < val_percent:\n                val_idx.append(i)\n            else:\n                train_idx.append(i)\n    \n        self.TRAIN = self.data.iloc[train_idx].reset_index(drop=True)\n        self.VALID = self.data.iloc[val_idx].reset_index(drop=True)\n\n\n    def __kFoldSplit__(self):\n        # Divide os dados em treino e validação com 80/20\n        train_data, val_data = train_test_split(self.data, test_size=0.4, random_state=42)\n\n        # Resetando o índice após o split\n        self.TRAIN = train_data.reset_index(drop=True)  # Resetando o índice do dataset de treino\n        self.VALID = val_data.reset_index(drop=True)    # Resetando o índice do dataset de validação\n\n\n    def __len__(self):\n        return len(self.data)\n\n    def __apply_transform__(self, img):\n        return self.transform(image=img)[\"image\"]\n\n    def __get_image__(self, idx):\n        img_path = os.path.join(self.DATASET_PATH, self.data.iloc[idx][\"file\"])\n        return np.array(Image.open(img_path).convert(\"RGB\"))\n\n    def __getitem__(self, idx):\n\n        if idx in self._cache:\n            self._cache.move_to_end(idx)\n            img, y = self._cache[idx]\n            return img.clone(), y.clone()\n\n        img = self.__get_image__(idx)\n\n        if self.USE_TRANSFORM:\n            img = self.__apply_transform__(img)\n\n        # Target\n        if self.USE_SCALER and \"DELTA_SCALED\" in self.data.columns:\n            y = torch.tensor(self.data.iloc[idx][\"DELTA_SCALED\"], dtype=torch.float32)\n        else:\n            y = torch.tensor(self.data.iloc[idx][\"deltaH_cm\"], dtype=torch.float32)\n\n        self._cache[idx] = (img, y)\n        self._cache.move_to_end(idx)\n        if len(self._cache) > self.cache_size:\n            self._cache.popitem(last=False)\n\n        return img.clone(), y.clone()\n\n\n    def _sample_(self):\n        # escolhe índice aleatório\n        idx = random.randrange(len(self.data))\n    \n        # carrega imagem\n        img = self.__get_image__(idx)\n    \n        # aplica transform se existir\n        if self.USE_TRANSFORM:\n            img = self.__apply_transform__(img)\n    \n        # se for tensor: converte para numpy para plotar\n        if isinstance(img, torch.Tensor):\n            img = img.cpu().numpy()\n            img = np.transpose(img, (1, 2, 0))  # C,H,W -> H,W,C\n    \n            # desfaz Normalize (imagem volta ao range real)\n            mean = np.array([0.485, 0.456, 0.406])\n            std  = np.array([0.229, 0.224, 0.225])\n            img = (img * std + mean).clip(0, 1)\n    \n        # plota\n        plt.figure(figsize=(5, 5))\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title(f\"Sample idx: {idx}\")\n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:36:38.434944Z","iopub.execute_input":"2025-12-12T23:36:38.435164Z","iopub.status.idle":"2025-12-12T23:36:38.454317Z","shell.execute_reply.started":"2025-12-12T23:36:38.435148Z","shell.execute_reply":"2025-12-12T23:36:38.453702Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Image Training Sample","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport random\nimport torch\nimport cv2\n\ndataset = CustomDataset(\n    data=SETTINGS.DATASET, image_size=(120, 120), \n    DATASET_PATH=SETTINGS.TRAIN_DATASET_DIR, use_transform=True, is_valid=False)\n\ndataset._sample_()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:36:38.455108Z","iopub.execute_input":"2025-12-12T23:36:38.455445Z","iopub.status.idle":"2025-12-12T23:36:38.636455Z","shell.execute_reply.started":"2025-12-12T23:36:38.455418Z","shell.execute_reply":"2025-12-12T23:36:38.635813Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 500x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# Engine","metadata":{}},{"cell_type":"code","source":"\nclass Engine():\n    def __init__(self, debug: bool = False):\n        super().__init__()\n\n        self.retraining = None\n\n        self.best_metric_value = float(\"inf\")  # Inicializa o valor da melhor métrica (loss) como infinidade\n\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.debug = debug\n\n        if SETTINGS.USE_SCALER:\n            self.scaler = SETTINGS.SCALER\n            self.scaler_y_mean = self.scaler.mean_.tolist()\n            self.scaler_y_scale = self.scaler.scale_.tolist()\n        else:\n            self.scaler_y_mean = 0\n            self.scaler_y_scale = 1\n            \n        self.model_loaded = False\n        self.cache_size = 100\n        self.image_size = (120, 120)\n        \n        # Checkpoints + History\n        self.history_replaced = False\n        self.default_history = {\n                    \"epoch\": [],\n                    \"train_loss\": [],\n                    \"val_loss\": [],\n                    \"test_loss\": [],   \n                    \"lr_backbone\": [],       \n                    \"lr_head\": [],      \n                    \"time_per_epoch\": [],\n                    \"run_range\": []\n                }\n\n\n        self.primary_history = self.temp_history = copy.deepcopy(self.default_history)\n        self.checkpoint = {\"history\": self.default_history}\n\n        # Controle Range e Epoch\n        self.range_initial = 0\n        self.start_epoch = 0\n\n    # ========================================\n    # Optimizer builder\n    # ========================================\n    def build_optimizer(self, from_scratch: bool = True):\n        # --- Monta trainable params ---\n        if hasattr(self.model, \"parameter_groups\"):\n            # Sempre use parameter_groups do modelo (mesmo quando from_scratch=True)\n            # parameter_groups deve retornar lista de dicts no formato [{\"params\": [...], \"lr\": lr_backbone}, {\"params\":[...],\"lr\": lr_head}]\n            self.trainable_params = self.model.parameter_groups(lr_backbone=self.lr_backbone, lr_head=self.lr_head)\n        else:\n            # fallback: lista simples de parâmetros treináveis\n            self.trainable_params = [p for p in self.model.parameters() if p.requires_grad]\n    \n        if len(self.trainable_params) == 0:\n            raise RuntimeError(\"Nenhum parâmetro marcado como treinável.\")\n    \n        # --- Cria o optimizer mantendo a sua lógica original ---\n        if self.optimizer_name == \"adamw\":\n            if isinstance(self.trainable_params[0], dict):\n                # Já tem os LRs definidos nos grupos\n                self.optimizer = AdamW(self.trainable_params, weight_decay=self.weight_decay)\n            else:\n                # lista simples -> usa learning_rate geral\n                self.optimizer = AdamW(self.trainable_params, lr=self.learning_rate, weight_decay=self.weight_decay)\n    \n        elif self.optimizer_name == \"sgdw\":\n            if isinstance(self.trainable_params[0], dict):\n                self.optimizer = SGDW(self.trainable_params, momentum=0.9, weight_decay=self.weight_decay)\n            else:\n                self.optimizer = SGDW(self.trainable_params, lr=self.learning_rate, momentum=0.9, weight_decay=self.weight_decay)\n    \n        else:\n            raise ValueError(f\"Optimizer '{self.optimizer_name}' não suportado.\")\n    \n        # Carrega estado do checkpoint se necessário (somente quando retomando)\n        if not from_scratch and hasattr(self, \"ckpt\"):\n            self.optimizer.load_state_dict(self.ckpt[\"optimizer_state\"])\n            print(\"Optimizer carregado com os valores salvos no checkpoint.\")\n    \n        # Debug: printar LRs de cada grupo\n        if self.debug:\n            for i, g in enumerate(self.optimizer.param_groups):\n                lr_print = g.get(\"lr\", None)\n                print(f\"Grupo {i}: lr = {lr_print}, parâmetros = {len(g['params'])}\")\n\n\n\n    # ========================================\n    # Scheduler\n    # ========================================\n    def build_scheduler(self, from_scratch: bool = True):\n        if self.use_schedule:\n            if self.schedule_name == \"cosineannealinglr\":\n                self.scheduler = CosineAnnealingLR(self.optimizer, T_max=self.epochs, eta_min=1e-6)\n            \n            elif self.schedule_name == \"cosineannelingwarm\":\n                warmup_percentage = self.kwargs.get('warmup_percentage', 0.1)\n                warmup_epochs = max(2, int(warmup_percentage * self.epochs))\n\n                warmup = LinearLR(self.optimizer, start_factor=0.01, total_iters=warmup_epochs)\n                cosine = CosineAnnealingLR(self.optimizer, T_max=self.epochs - warmup_epochs, eta_min=1e-8)\n\n                self.scheduler = SequentialLR(self.optimizer, schedulers=[warmup, cosine], milestones=[warmup_epochs])\n\n            if not from_scratch:\n                self.scheduler.load_state_dict(self.ckpt[\"scheduler_state\"])\n                print(\"Scheduler carregado com os valores salvos no checkpoint.\")\n        else:\n            self.scheduler = None\n\n    # ========================================\n    # Load Model\n    # ========================================\n    def load_model(self, custom_model_pth=None, custom: bool = False):\n        if custom:\n            self.retraining = True\n            \n            if custom_model_pth is None:\n                raise ValueError(\"custom_model é None mas custom==True\")\n\n            self.ckpt = torch.load(custom_model_pth, map_location=self.device)\n\n            metadata = self.ckpt.get(\"metadata\", {})\n\n            if self.unfreeze_all:\n                self.unfreeze_all = metadata.get(\"unfreeze_all\", False)\n                \n            self.use_head  = metadata.get(\"use_head\", False)\n            self.backbone_name = metadata.get(\"backbone_name\", self.backbone_name)\n\n            # Carregar o tamanho de imagem treinado\n            self.image_size = metadata.get(\"training_image_size\", (120,120))\n\n            # Carrega a melhor loss do modelo\n            self.best_metric_value = self.ckpt.get(\"best_val_loss\", float(\"inf\")) \n            print(f\"A melhor loss carrega foi: {self.best_metric_value:.4f} e alterada para {self.best_metric_value*2.5}\")\n            self.best_metric_value = 2.5*self.best_metric_value\n            \n            self.model = NewDirectModel(backbone_name=self.backbone_name, unfreeze_all=self.unfreeze_all, use_head=self.use_head, image_size=self.image_size).to(self.device)\n\n            # Carregar os pesos treinados\n            self.model.load_state_dict(self.ckpt[\"model_state\"], strict=False)\n\n            # Restaurar scheduler/optimizer names\n            self.optimizer_name = metadata.get(\"optimizer_name\", \"AdamW\")\n            self.schedule_name  = metadata.get(\"schedule_name\", None)\n\n            if self.use_last_lr:\n                self.learning_rate = self.ckpt.get('last_lr', self.learning_rate)\n                self.build_optimizer(from_scratch=False)\n                self.build_scheduler(from_scratch=False)\n                \n            else:\n                self.build_optimizer(from_scratch=True)\n                self.build_scheduler(from_scratch=True)\n\n            self.primary_history = self.ckpt.get(\"history\", self.default_history)\n            self.start_epoch = len(self.primary_history.get(\"epoch\", []))\n            self.range_initial = len(self.primary_history.get('val_loss', []))\n            \n        else:\n            self.model = NewDirectModel(backbone_name=self.backbone_name, unfreeze_all=self.unfreeze_all,use_head=self.use_head, image_size=self.image_size).to(self.device)\n\n            self.image_size = self.model.image_size\n            self.model_loaded = True\n\n            self.build_optimizer(from_scratch=True)\n            self.build_scheduler(from_scratch=True)\n\n        # Contagem dos parâmetros\n        if isinstance(self.trainable_params[0], dict):  # Veio de parameter_groups\n            n_trainable = sum(p.numel() for g in self.trainable_params for p in g[\"params\"])\n        else:\n            n_trainable = sum(p.numel() for p in self.trainable_params)\n\n        n_total = sum(p.numel() for p in self.model.parameters())\n        print(f\"Parâmetros treináveis: {n_trainable} / {n_total}\")\n\n    # ========================================\n    # Set parameters\n    # ========================================\n    def set_parameters(self, batch_size: int, epochs: int, patience: int, \n                       use_transform: bool = True, backbone_name: str = \"resnet\", learning_rate = 0.001,weight_decay: float = 1e-4, \n                       use_schedule: bool = True, unfreeze_all: bool = False, optimizer: str = 'AdamW', \n                       schedule: str = \"CosineAnnelingWarm\", use_head: bool = False, SPLIT_OPTION: str = 'SKLEARN', image_size:tuple=(120,120), **kwargs):\n        \n        self.weight_decay = weight_decay\n        \n        self.batch_size = batch_size\n        self.learning_rate = learning_rate\n        self.epochs = epochs\n        self.patience = patience\n        self.USE_TRANSFORM = use_transform\n        self.backbone_name = backbone_name\n        self.use_schedule = use_schedule\n        self.unfreeze_all = unfreeze_all\n        self.optimizer_name = optimizer.lower()\n        self.schedule_name = schedule.lower()\n        self.use_head = use_head\n        self.SPLIT_OPTION = SPLIT_OPTION\n        self.image_size = image_size\n\n        self.kwargs = kwargs\n\n        self.lr_head = self.kwargs.get(\"lr_head\", self.learning_rate)\n        self.lr_backbone = self.kwargs.get(\"lr_backbone\", self.learning_rate)\n\n\n\n    # ========================================\n    # Run Epoch\n    # ========================================\n    def run(self, output_dir, custom_model=None, show_all_epochs: bool = True, use_last_lr: bool = True):\n        self.use_last_lr = use_last_lr\n        self.show_all_epochs = show_all_epochs\n        self.output_dir = output_dir\n        os.makedirs(output_dir, exist_ok=True)\n        self.history_replaced = True\n\n        if custom_model is None:\n            self.load_model(custom=False)\n            \n        else:\n            self.load_model(custom=True, custom_model_pth=custom_model)\n\n        # Criar o nome do modelo a ser salvo\n        self.build_model_name()\n\n        self._printer(\"show_settings\")\n        print(\"================================================\")\n\n        # Raise caso split option nao estiver nas disponiveis.\n        if not self.SPLIT_OPTION.upper() in ['SKLSPLIT', \"HASHSPLIT\", \"RFSPLIT\"]:\n            raise ValueError(f\"SPLIT_OPTION '{self.SPLIT_OPTION.upper()}' inválido, esperado: ['SKLSPLIT', 'HASHSPLIT', 'RFSPLIT']\")\n\n        # Utilizar sklearn split ou hash split\n        if self.SPLIT_OPTION.upper() in ['SKLSPLIT', \"HASHSPLIT\"]:\n            tmp_dataset = CustomDataset(SETTINGS.DATASET, image_size=self.image_size, SPLIT_OPTION=self.SPLIT_OPTION)\n            \n            print(f\"tmp_dataset: {len(tmp_dataset)}\")\n\n            self.TRAIN = CustomDataset(tmp_dataset.TRAIN, image_size=self.image_size, is_valid=False, DATASET_PATH=SETTINGS.TRAIN_DATASET_DIR,)\n            self.VALID = CustomDataset(tmp_dataset.VALID, image_size=self.image_size, is_valid=True, DATASET_PATH=SETTINGS.VALID_DATASET_DIR)\n\n            # Setar o dataset de test (sempre a repartição vinda do RoboFlow)\n            self.TEST = CustomDataset(SETTINGS.TEST_DATASET, DATASET_PATH=SETTINGS.TEST_DATASET_DIR, image_size=self.image_size, cache_size=self.cache_size, is_valid=True)\n\n\n            # Armazenar o tamanho dos datasets para adicionar no checkpoint -> metadata\n            self.TRAIN_SIZE = len(self.TRAIN)\n            self.VALID_SIZE = len(self.VALID)\n            self.TEST_SIZE = len(self.TEST)\n\n            print(f\"Train: {len(self.TRAIN)} [{len(self.TRAIN)/(len(tmp_dataset))*100:.2f}]\")\n            print(f\"VALID: {len(self.VALID)} [{len(self.VALID)/(len(tmp_dataset))*100:.2f}]\")\n        \n            train_loader = DataLoader(self.TRAIN, batch_size=self.batch_size, shuffle=True, pin_memory=True)\n            val_loader = DataLoader(self.VALID, batch_size=self.batch_size, shuffle=False, pin_memory=True)\n            test_loader = DataLoader(self.TEST, batch_size=self.batch_size, shuffle=False, pin_memory=True)\n\n\n            best_metric_value, history = self._run_epochs(train_loader, val_loader, test_loader)\n            self.primary_history = copy.deepcopy(history)\n\n\n        # Utilizar o split gerado pelo RoboFlow\n        else:\n            self.TRAIN = CustomDataset(SETTINGS.TRAIN_DATASET, DATASET_PATH=SETTINGS.TRAIN_DATASET_DIR, image_size=self.image_size, cache_size=self.cache_size, is_valid=False)\n            self.VALID = CustomDataset(SETTINGS.VALID_DATASET, DATASET_PATH=SETTINGS.VALID_DATASET_DIR, image_size=self.image_size, cache_size=self.cache_size, is_valid=True)\n\n            # Setar o dataset de test (sempre a repartição vinda do RoboFlow)\n            self.TEST = CustomDataset(SETTINGS.TEST_DATASET, DATASET_PATH=SETTINGS.TEST_DATASET_DIR, image_size=self.image_size, cache_size=self.cache_size, is_valid=True)\n\n            # Armazenar o tamanho dos datasets para adicionar no checkpoint -> metadata\n            self.TRAIN_SIZE = len(self.TRAIN)\n            self.VALID_SIZE = len(self.VALID)\n            self.TEST_SIZE = len(self.TEST)\n            \n            # Se não usar sklearn split, usa os datasets normais\n            train_loader = DataLoader(self.TRAIN, batch_size=self.batch_size, shuffle=True, pin_memory=True)\n            val_loader = DataLoader(self.VALID, batch_size=self.batch_size, shuffle=False, pin_memory=True)\n            test_loader = DataLoader(self.TEST, batch_size=self.batch_size, shuffle=False, pin_memory=True)\n\n            best_metric_value, history = self._run_epochs(train_loader, val_loader, test_loader)\n            self.primary_history = copy.deepcopy(history)\n\n        \n        print(f\"\\nTreinamento finalizado e salvo em {self.output_dir}\")\n\n    # ========================================\n    # Run epochs\n    # ========================================\n    def _run_epochs(self, train_loader, val_loader, test_loader, fold_idx=None):\n        criterion = nn.L1Loss()  # Função de perda (L1 Loss para regressão)\n        #criterion = nn.MSELoss()\n        \n        use_amp = torch.cuda.is_available()                 # Verificar se a aceleração por ponto flutuante (amp) pode ser usada\n        scaler_amp = torch.amp.GradScaler(enabled=use_amp)  # Usado para mixed-precision (caso tenha suporte a AMP)\n\n        current_patience = 0  # Contador de paciência para early stopping\n        self.temp_history = copy.deepcopy(self.default_history)  # Inicializa o histórico temporário\n\n        # Loop pelas épocas\n        for e in tqdm(range(self.epochs), desc=f\"Epochs\", leave=False):\n            early_time = time.time()  # Marca o tempo de início da época\n            \n            # ======== Treinamento e Validação ========\n            train_loss = self.train_one_epoch(train_loader, criterion)  # Treinamento de uma época\n            val_loss = self.validate_one_epoch(val_loader, criterion)  # Validação de uma época\n            test_loss = self.test_one_epoch(test_loader, criterion)\n            \n            # Calcula o tempo que levou para a época\n            self.last_deltaTime = time.time() - early_time\n            self.temp_history[\"time_per_epoch\"].append(self.last_deltaTime)\n            \n            # Atualiza o scheduler (caso esteja sendo utilizado)\n            if self.scheduler is not None:\n                self.scheduler.step()\n\n            # Registra os resultados da época\n            self.temp_history[\"epoch\"].append(self.start_epoch + e + 1)\n            self.temp_history[\"train_loss\"].append(train_loss)\n            self.temp_history[\"test_loss\"].append(test_loss)\n            self.temp_history[\"val_loss\"].append(val_loss)\n\n            # Atualizar os valores de lr_backbone e lr_head\n            self.lr_backbone = self.optimizer.param_groups[0][\"lr\"]\n            if len(self.optimizer.param_groups) > 1:\n                self.lr_head = self.optimizer.param_groups[1][\"lr\"]\n            else:\n                self.lr_head = self.lr_backbone\n\n            \n            self.temp_history[\"lr_backbone\"].append(self.lr_backbone)\n            self.temp_history[\"lr_head\"].append(self.lr_head)\n\n\n            # ======== Checkpoint ========\n            # Se a perda de validação for melhor (menor), salva o checkpoint\n            if val_loss < self.best_metric_value:\n                print(f\"Epoch {e+1}/{self.epochs} | train_loss: {train_loss:.5f} val_loss: {val_loss:.5f} | test_loss: {test_loss:.5f}\"\n                      f\"| lr_head: {self.lr_head:.6f} | lr_backbone: {self.lr_backbone:.8f} (*)\")\n                \n                self.best_metric_value = val_loss  # Atualiza a melhor métrica\n                current_patience = 0               # Reseta o contador de paciência\n                \n                # Salva o checkpoint do modelo\n                self.checkpoint = self._save_checkpoint(\n                    fold_idx=fold_idx, epoch=self.start_epoch + e + 1, model_state=self.model.state_dict(),\n                    optimizer_state=self.optimizer.state_dict(), scheduler_state=self.scheduler.state_dict() if self.scheduler is not None else None,\n                    history=self.temp_history, best_val_loss= self.best_metric_value, learning_rate=self.learning_rate,\n                    epochs=self.epochs, batch_size=self.batch_size, device=str(self.device))\n                \n                # Salva o modelo\n                self._save_model(self.checkpoint)\n            else:\n                # Se a perda de validação não melhorou, incrementa o contador de paciência\n                if self.show_all_epochs:\n                    print(f\"Epoch {e+1}/{self.epochs} | train_loss: {train_loss:.5f} \"\n                          f\"val_loss: {val_loss:.5f} | test_loss: {test_loss:.5f} | lr: {self.optimizer.param_groups[0]['lr']:.6f}\")\n                current_patience += 1\n                \n                # Se a paciência atingir o valor máximo, aplica o early stopping\n                if current_patience >= self.patience:\n                    print(f\"Early stopping (epoch {self.start_epoch + e + 1})\")\n                    break\n\n        # Libera a memória da GPU (caso esteja utilizando CUDA)\n        torch.cuda.empty_cache()\n        return self.best_metric_value, self.temp_history\n\n\n    # =======================================\n    def train_one_epoch(self, train_loader, criterion):\n        self.model.train() \n        train_loss = 0.0  # Inicializa a variável para a perda total\n        total_batches = len(train_loader)  # Número total de lotes de dados\n        \n        # Loop pelos batches de dados\n        # for batch_idx, (img, y) in enumerate(train_loader):\n        for img, y in tqdm(train_loader, desc=\"Train batches\", leave=False):\n            img, y = img.to(self.device), y.to(self.device)  # Move as imagens e os rótulos para a GPU/CPU\n    \n            self.optimizer.zero_grad()  # Zera os gradientes acumulados\n    \n            # Passa a imagem pelo modelo\n            #outputs = self.model(img)  # O modelo recebe uma entrada de 4D (N, C, H, W)\n            outputs = self.model(img).squeeze(-1)\n            \n            # Calcula a perda\n            loss = criterion(outputs, y)\n            \n            # Realiza a retropropagação\n            loss.backward()\n            \n            # Atualiza os parâmetros do modelo\n            self.optimizer.step()\n            \n            # Acumula a perda\n            train_loss += loss.item() * img.size(0)  # Multiplica pela quantidade de exemplos no batch\n        \n        # Calcula a perda média da época\n        train_loss /= len(train_loader.dataset)\n        return train_loss  # Retorna a perda média de treinamento\n\n\n    # ========================================\n    # Validação por uma única época\n    # ========================================\n    def validate_one_epoch(self, val_loader, criterion):\n        self.model.eval()  # Coloca o modelo em modo de avaliação\n        \n        val_loss = 0.0  # Inicializa a variável para a perda total\n        total_batches = len(val_loader)  # Número total de lotes de validação\n        \n        with torch.no_grad():  # Desliga o cálculo de gradientes\n            # Loop pelos batches de validação\n\n            # for batch_idx, (img, y) in enumerate(val_loader):\n            for img, y in tqdm(val_loader, desc=\"Valid batches\", leave=False):\n                img, y = img.to(self.device), y.to(self.device)  # Move as imagens e os rótulos para a GPU/CPU\n                \n                # Passa a imagem pelo modelo\n                outputs = self.model(img).squeeze(-1)  # Remove a última dimensão (para ajustes no modelo)\n    \n                # Calcula a perda\n                loss = criterion(outputs, y)\n                \n                # Acumula a perda\n                val_loss += loss.item() * img.size(0)  # Multiplica pela quantidade de exemplos no batch\n        \n        # Calcula a perda média da época de validação\n        val_loss /= len(val_loader.dataset)\n        \n        return val_loss  # Retorna a perda média de validação\n\n    # ========================================\n    # Testar uma época\n    # ========================================\n    def test_one_epoch(self, test_loader, criterion):\n        self.model.eval()  # Coloca o modelo em modo de avaliação\n        \n        test_loss = 0.0  # Inicializa a variável para a perda total\n        total_batches = len(test_loader)  # Número total de lotes de validação\n        \n        with torch.no_grad():  # Desliga o cálculo de gradientes\n\n            # for batch_idx, (img, y) in enumerate(val_loader):\n            for img, y in tqdm(test_loader, desc=\"Test batches\", leave=False):\n                img, y = img.to(self.device), y.to(self.device)  # Move as imagens e os rótulos para a GPU/CPU\n                \n                # Passa a imagem pelo modelo\n                outputs = self.model(img).squeeze(-1)  # Remove a última dimensão (para ajustes no modelo)\n    \n                # Calcula a perda\n                loss = criterion(outputs, y)\n                \n                # Acumula a perda\n                test_loss += loss.item() * img.size(0)  # Multiplica pela quantidade de exemplos no batch\n        \n        # Calcula a perda média da época de validação\n        test_loss /= len(test_loader.dataset)\n        \n        return test_loss  # Retorna a perda média de validação\n\n    def _save_checkpoint(self, fold_idx, epoch, model_state, optimizer_state, scheduler_state, history, best_val_loss,\n        learning_rate, epochs, batch_size, device):\n\n        return {\n            \"last_fold\": fold_idx,\n            \"last_epoch\": epoch + 1,\n            \"model_state\": model_state,\n            \"optimizer_state\": optimizer_state,\n            \"scheduler_state\": scheduler_state,\n            \"history\": history,\n            \"best_val_loss\": best_val_loss,\n            \"metadata\": {\n                \"training_learning_rate\": learning_rate,\n                \"training_num_epochs\": epochs,\n                \"training_batch_size\": batch_size,\n                \"training_device\": device,\n                \"training_date\": datetime.today().strftime(\"%Y_%m_%d\"),\n                \"training_dataset\": \"UTM_DATASET_\" + SETTINGS.DATASET_NAME,\n                \"training_image_size\":self.model.image_size,\n                \"training_size\": self.TRAIN_SIZE,\n                \"validation_size\": self.VALID_SIZE,\n                \"test_size\": self.TEST_SIZE,\n                \"weight_decay\": self.weight_decay,\n                \"backbone_name\": self.backbone_name,\n                \"use_schedule\": self.use_schedule,\n                \"unfreeze_all\": self.unfreeze_all,\n                \"optimizer_name\": self.optimizer_name,\n                \"schedule_name\": self.schedule_name,\n                \"use_head\":self.use_head,\n                \"use_augmentation\": self.USE_TRANSFORM},\n            \"scaler_y_mean\": self.scaler_y_mean,\n            \"scaler_y_scale\": self.scaler_y_scale,\n        }\n\n    def _save_model(self, checkpoint):\n        save_path = os.path.join(self.output_dir, f\"{self.model_name}.pth\")\n        torch.save(checkpoint, save_path)\n\n    def build_model_name(self):\n        name = self.backbone_name\n        img_x, img_y = self.image_size\n        training_date = datetime.today().strftime(\"%Y_%m_%d\")\n\n        split_option = self.SPLIT_OPTION if self.SPLIT_OPTION.upper() in ['SKLSPLIT', \"HASHSPLIT\"] else 'RFSplit'\n        \n        freeze_option = \"UnfreezeAll\" if self.unfreeze_all else \"Unfreeze\"\n        head_option = \"WithHead\" if self.use_head else \"NoHead\"\n        optimizer_option = self.optimizer_name.upper()\n\n        # Modelo está sendo retreinado, i.e., adicionar \"retrained\" no nome do modelo\n        if self.retraining:\n            self.model_name = \"_\".join([name, str(img_x) +'x'+str(img_y), training_date, split_option, freeze_option, head_option, optimizer_option, \"retrained\"])\n            \n        else:\n            self.model_name = \"_\".join([name, str(img_x) +'x'+str(img_y), training_date, split_option, freeze_option, head_option, optimizer_option])\n        \n    def _printer(self, arg):\n        if arg == \"show_settings\":\n            print(\"================================================\")\n            print(\"Training Settings\")\n            print(\"================================================\")\n            print(\n                f\"Model: {self.model_name}\\n\"\n                f\"Backbone: {self.backbone_name}\\n\"\n                f\"Batch Size: {self.batch_size}\\n\"\n                f\"Learning Rate: {self.learning_rate}\\n\"\n                f\"Weight Decay: {self.weight_decay}\\n\"\n                f\"Image Size: {self.image_size}\\n\"\n                f\"SPLIT_OPTION: {self.SPLIT_OPTION}\\n\"\n                f\"Epochs: {self.epochs}\\n\"\n                f\"Patience: {self.patience}\\n\"\n                f\"Schedule: {self.schedule_name}\\n\"\n                f\"Optimizer: {self.optimizer_name}\\n\"\n                f\"Unfreeze All: {self.unfreeze_all}\\n\"\n                f\"Use Augmentation: {self.USE_TRANSFORM}\\n\"\n                f\"Use Schedule: {self.use_schedule}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:36:38.638513Z","iopub.execute_input":"2025-12-12T23:36:38.638798Z","iopub.status.idle":"2025-12-12T23:36:38.687611Z","shell.execute_reply.started":"2025-12-12T23:36:38.638783Z","shell.execute_reply":"2025-12-12T23:36:38.686746Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Treinamento","metadata":{}},{"cell_type":"code","source":"weight_decays = [w * 0.001 for w in np.arange(1/4, 1/2, 0.05)]\n\n# Lr para SGDW\nlearning_rates_SGDW = [lr * 0.1   for lr in np.arange(1/32, 1/16, 0.01)]\n\n#Lr para AdamW\nlearning_rates_AdamW = [lr * 0.1   for lr in np.arange(1/128, 1/256)]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:36:38.688301Z","iopub.execute_input":"2025-12-12T23:36:38.688553Z","iopub.status.idle":"2025-12-12T23:36:38.707307Z","shell.execute_reply.started":"2025-12-12T23:36:38.688534Z","shell.execute_reply":"2025-12-12T23:36:38.706614Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"TRAINING = False\n\nif TRAINING:\n    print(\"TRAINING\")\n    engine = Engine()\n\n    # Configurar parâmetros\n    engine.set_parameters(\n        batch_size=128,\n        lr_backbone=3e-5,        # LR para backbone\n        lr_head=1e-3,            # LR para head/classifier\n        epochs=100, patience=1000,\n        warmup_percentage=0.2,   # 10% de warmup]\n        schedule_name = 'cosineannelingwarm',\n        use_transform=True, use_schedule=True,\n        SPLIT_OPTION='HashSplit',\n        backbone_name='efficientnet_lite',\n        unfreeze_all=False, use_head=False, image_size=(120,120), optimizer='AdamW')\n    \n    \n    #  Treinamento\n    engine.run(output_dir=\"/kaggle/working/\", show_all_epochs=True, use_last_lr=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:36:38.708088Z","iopub.execute_input":"2025-12-12T23:36:38.708372Z","iopub.status.idle":"2025-12-12T23:42:24.446798Z","shell.execute_reply.started":"2025-12-12T23:36:38.708355Z","shell.execute_reply":"2025-12-12T23:42:24.445557Z"}},"outputs":[{"name":"stdout","text":"TRAINING\n[EfficientNet] Features [6] Descongelado\n[EfficientNet] Features [7] Descongelado\n[EfficientNet] Features [8] Descongelado\n[EfficientNet] classificador (fc) descongelado\nBackbone params: 68\nHead params: 2\nParâmetros treináveis: 3157021 / 4008829\n================================================\nTraining Settings\n================================================\nModel: efficientnet_lite_120x120_2025_12_12_HashSplit_Unfreeze_NoHead_ADAMW\nBackbone: efficientnet_lite\nBatch Size: 128\nLearning Rate: 0.001\nWeight Decay: 0.0001\nImage Size: (120, 120)\nSPLIT_OPTION: HashSplit\nEpochs: 100\nPatience: 1000\nSchedule: cosineannelingwarm\nOptimizer: adamw\nUnfreeze All: False\nUse Augmentation: True\nUse Schedule: True\n================================================\ntmp_dataset: 155008\nTrain: 108475 [69.98]\nVALID: 46533 [30.02]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epochs:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c782fa66c0c4a519ba42107210d50e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Train batches:   0%|          | 0/848 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e9bd7f357734b58ad957792e980c4bd"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2035085527.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#  Treinamento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/working/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_all_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_last_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_47/1947250211.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_dir, custom_model, show_all_epochs, use_last_lr)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mbest_metric_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/1947250211.py\u001b[0m in \u001b[0;36m_run_epochs\u001b[0;34m(self, train_loader, val_loader, test_loader, fold_idx)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;31m# ======== Treinamento e Validação ========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Treinamento de uma época\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Validação de uma época\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/1947250211.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, train_loader, criterion)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Loop pelos batches de dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# for batch_idx, (img, y) in enumerate(train_loader):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train batches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Move as imagens e os rótulos para a GPU/CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/2623765137.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSE_TRANSFORM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__apply_transform__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/2623765137.py\u001b[0m in \u001b[0;36m__apply_transform__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__apply_transform__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_image__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albumentations/core/composition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_track_transform_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_data_post_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albumentations/core/transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_with_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albumentations/core/transforms_interface.py\u001b[0m in \u001b[0;36mapply_with_params\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mtarget_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key2func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                     res[key] = ensure_contiguous_output(\n\u001b[0;32m--> 310\u001b[0;31m                         \u001b[0mtarget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_contiguous_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m                     )\n\u001b[1;32m    312\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albumentations/augmentations/blur/transforms.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, img, radius, alias_blur, **params)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m         \"\"\"\n\u001b[0;32m-> 1487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfblur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefocus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malias_blur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albumentations/augmentations/blur/functional.py\u001b[0m in \u001b[0;36mdefocus\u001b[0;34m(img, radius, alias_blur)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maliased_disk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmaX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malias_blur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albucore/utils.py\u001b[0m in \u001b[0;36mwrapped_function\u001b[0;34m(img, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albucore/decorators.py\u001b[0m in \u001b[0;36mwrapped_function\u001b[0;34m(img, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNUM_MULTI_CHANNEL_DIMENSIONS\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMONO_CHANNEL_DIMENSIONS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albumentations/augmentations/pixel/functional.py\u001b[0m in \u001b[0;36mconvolve\u001b[0;34m(img, kernel)\u001b[0m\n\u001b[1;32m   4064\u001b[0m     \"\"\"\n\u001b[1;32m   4065\u001b[0m     \u001b[0mconv_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_process_in_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4066\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconv_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albucore/utils.py\u001b[0m in \u001b[0;36m__process_fn\u001b[0;34m(img, *process_args, **process_kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mprocess_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__process_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":12},{"cell_type":"markdown","source":"# Retreinamento","metadata":{}},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nRETRAINING = True\n\nif RETRAINING:\n    print(\"RETRAINING\")\n    model_wrapper_path = \"/kaggle/working/resnet_120x120_2025_12_12_HashSplit_Unfreeze_NoHead_ADAMW_retrained.pth\"\n\n    engine = Engine()\n    \n    engine.set_parameters(\n        batch_size=128,\n        lr_backbone=3e-3,       \n        lr_head=1e-2,         \n        epochs=30,\n        patience=1000,\n        warmup_percentage=0.2,   # 10% de warmup]\n        schedule_name = 'cosineannelingwarm',\n        use_transform=True,  use_schedule=True,\n        SPLIT_OPTION='HashSplit',\n        backbone_name='efficientnet_lite',\n        unfreeze_all=False,  use_head=False,\n        image_size=(120,120),\n        optimizer='AdamW')\n    \n    \n    engine.run(output_dir=\"/kaggle/working/\", custom_model=model_wrapper_path, show_all_epochs=True, use_last_lr=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:46:15.298285Z","iopub.execute_input":"2025-12-12T23:46:15.298608Z"}},"outputs":[{"name":"stdout","text":"RETRAINING\nA melhor loss carrega foi: 0.2379 e alterada para 0.5946956966027088\nResnet Features [3] Descongelado\nResnet Features [4] Descongelado\nBackbone params: 30\nHead params: 2\nParâmetros treináveis: 10493953 / 11177025\n================================================\nTraining Settings\n================================================\nModel: resnet_120x120_2025_12_12_HashSplit_Unfreeze_NoHead_ADAMW_retrained\nBackbone: resnet\nBatch Size: 128\nLearning Rate: 0.001\nWeight Decay: 0.0001\nImage Size: (120, 120)\nSPLIT_OPTION: HashSplit\nEpochs: 30\nPatience: 1000\nSchedule: cosineannelingwarm\nOptimizer: adamw\nUnfreeze All: False\nUse Augmentation: True\nUse Schedule: True\n================================================\ntmp_dataset: 155008\nTrain: 108475 [69.98]\nVALID: 46533 [30.02]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epochs:   0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8171960bcb6346559911c860669acf41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Train batches:   0%|          | 0/848 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0ac10b18fea433a82ab29cfba0d6548"}},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"86 # Inferencia","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torchvision import models\n\n\nclass NewDirectModel_Inference(nn.Module):\n    def __init__(self, backbone_name: str, unfreeze_all: bool = False, debug: bool = False):\n        super().__init__()\n        self.model_name = backbone_name\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.debug = debug\n\n        self.use_head = False   # será substituído pelo checkpoint\n        self.unfreeze_all = unfreeze_all\n        self.image_size = (224, 224)\n\n        self.to(self.device)\n\n        self.transform = A.Compose([\n            A.Resize(224, 224),\n            A.Normalize(mean=[0.485, 0.456, 0.406],\n                        std=[0.229, 0.224, 0.225]),\n            ToTensorV2(),\n        ])\n\n\n    # ---------------------------------------------------------\n    # HEAD MLP\n    # ---------------------------------------------------------\n    def build_head(self, output_features):\n        self.head = nn.Sequential(\n            nn.Linear(output_features, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(256, 128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(128, 1),\n        )\n\n        if self.debug:\n            print(f\"Head criada com {output_features} features → 256 → 128 → 1\")\n\n    # ---------------------------------------------------------\n    # FORWARD\n    # ---------------------------------------------------------\n    def forward(self, x):\n        x = x.to(self.device)\n\n        if hasattr(self, \"head\") and self.head is not None:\n            feats = self.backbone(x)\n            return self.head(feats)\n\n        return self.backbone(x)\n\n    # ---------------------------------------------------------\n    # LOAD MODEL COMPLETO\n    # ---------------------------------------------------------\n    def load_model(self, path_or_ckpt):\n        if isinstance(path_or_ckpt, str):\n            ckpt = torch.load(path_or_ckpt, map_location=self.device)\n        else:\n            ckpt = path_or_ckpt\n\n        meta = ckpt.get(\"metadata\", {})\n        self.model_name = meta.get(\"backbone_name\", self.model_name)\n        self.use_head = meta.get(\"use_head\", False)\n\n        # Recria a arquitetura exatamente igual do treino\n        self.load_backbone()\n\n        # Agora carrega os pesos\n        state = ckpt.get(\"model_state\", None)\n        if state is None:\n            raise ValueError(\"Checkpoint sem 'model_state'\")\n\n        missing, unexpected = self.load_state_dict(state, strict=False)\n\n        if self.debug:\n            print(\"Missing keys:\", missing)\n            print(\"Unexpected keys:\", unexpected)\n\n        self.to(self.device)\n        self.eval()\n        return self\n\n    # ---------------------------------------------------------\n    # CONSTRUIR BACKBONE\n    # ---------------------------------------------------------\n    def load_backbone(self):\n        name = self.model_name.lower()\n\n        # ------------------- RESNET18 -------------------\n        if name in (\"resnet\", \"resnet18\"):\n            m = models.resnet18(weights=None)  # IMPORTANTE: NÃO USAR pretrained!\n\n            out_feats = m.fc.in_features\n\n            if self.use_head:\n                m.fc = nn.Identity()\n                self.build_head(out_feats)\n            else:\n                m.fc = nn.Linear(out_feats, 1)\n\n            self.backbone = m\n\n        # ------------------- EFFICIENTNET -------------------\n        elif name in (\"efficientnet_lite\", \"efficientnet_b0\"):\n            m = models.efficientnet_b0(weights=None)\n\n            out_feats = m.classifier[1].in_features\n\n            if self.use_head:\n                m.classifier[1] = nn.Identity()\n                self.build_head(out_feats)\n            else:\n                m.classifier[1] = nn.Linear(out_feats, 1)\n\n            self.backbone = m\n\n        else:\n            raise ValueError(f\"Backbone '{self.model_name}' inválido.\")\n\n    def predict(self, img):\n        img_tensor = self.transform(image=img)[\"image\"].unsqueeze(0)\n        self.eval()\n        img_tensor = img_tensor.to(self.device)\n    \n        with torch.no_grad():\n            output = self.forward(img_tensor)\n    \n        return output.item()\n\n\n\n# -------------------------------------------------------------\n# USO PARA INFERÊNCIA\n# -------------------------------------------------------------\nimport cv2 \nfrom PIL import Image\nimport numpy as np\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport matplotlib.pyplot as plt\n\n# Carregar imagem\nindex = SETTINGS.TEST_DATASET.loc[2]\npath = index[\"file\"]\nimg = np.array(Image.open(path).convert(\"RGB\"))\n\nplt.imshow(img); plt.axis(\"off\"); plt.show()\n\n\n# Carregar modelo\nmodel = NewDirectModel_Inference(\"efficientnet_lite\").load_model(\n    \"/kaggle/working/efficientnet_lite_2025_11_26_3k_head_SKLEARN.pth\"\n)\n\n# Fazer predição correta\noutput = model.predict(img)\n\nprint(\"Label correto:\", index[\"deltaH_cm\"])\nprint(\"Predição:\", output)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:42:24.449545Z","iopub.status.idle":"2025-12-12T23:42:24.449862Z","shell.execute_reply.started":"2025-12-12T23:42:24.449672Z","shell.execute_reply":"2025-12-12T23:42:24.449688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = np.array(Image.open(\"/kaggle/input/datatest/model3_box0_cls0_conf0.66.jpg\").convert(\"RGB\"))\n\nplt.imshow(img); plt.axis(\"off\"); plt.show()\n\n\ntransform = A.Compose([\n            #A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.2, p=0.5),\n            #A.RGBShift(r_shift_limit=5, g_shift_limit=5, b_shift_limit=5, p=0.3),\n            #A.ISONoise(color_shift=(0.005, 0.01), intensity=(0.05, 0.1), p=0.8),\n            #A.Perspective(scale=(0.01, 0.03), p=0.3),\n            A.Resize(224, 224),\n            A.Normalize(mean=[0.485, 0.456, 0.406],\n                        std=[0.229, 0.224, 0.225]),\n            ToTensorV2(),\n        ])\n\n\nimg_tensor = transform(image=img)[\"image\"].unsqueeze(0)\n# img_tensor é CHW normalizado\nimg_np = img_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()   # CHW → HWC\n\n# desfazer normalização para visualizar\nmean = np.array([0.485, 0.456, 0.406])\nstd  = np.array([0.229, 0.224, 0.225])\n\nimg_np = (img_np * std) + mean   # denormalizar\nimg_np = np.clip(img_np, 0, 1)\n\nplt.imshow(img_np)\nplt.axis(\"off\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:42:24.452171Z","iopub.status.idle":"2025-12-12T23:42:24.452708Z","shell.execute_reply.started":"2025-12-12T23:42:24.452518Z","shell.execute_reply":"2025-12-12T23:42:24.452535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nwith torch.no_grad():\n    output = model(img_tensor)\n\nprint(\"Predição:\", float(output.item()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T23:42:24.453904Z","iopub.status.idle":"2025-12-12T23:42:24.454184Z","shell.execute_reply.started":"2025-12-12T23:42:24.454063Z","shell.execute_reply":"2025-12-12T23:42:24.454076Z"}},"outputs":[],"execution_count":null}]}